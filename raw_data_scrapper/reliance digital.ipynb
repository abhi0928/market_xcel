{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e00079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.filedialog as fd\n",
    "from selenium.webdriver.common.by import By\n",
    "# root = tk.Tk()\n",
    "# file = fd.askopenfilename(parent=root, title='Choose a record file')\n",
    "# file2 = fd.askopenfilenames(parent=root, title='Choose a pdf files')\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from IPython.display import clear_output\n",
    "# root.destroy()\n",
    "from time import sleep\n",
    "import easygui\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from selenium import webdriver\n",
    "#set chromedriver.exe path\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.implicitly_wait(0)\n",
    "#maximize browser\n",
    "driver.maximize_window()\n",
    "#launch URL\n",
    "driver.get(\"https://www.reliancedigital.in/polycab-400-mm-elanza-pw01-wall-fan-white-grey/p/492664609\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eff758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver.implicitly_wait(2)\n",
    "cc=['RAC (Fixed speed)','Direct cool refrigerator','Ceiling Fans']\n",
    "\n",
    "list=[\n",
    "'https://www.reliancedigital.in/air-conditioners/c/S101510?searchQuery=Air%20Conditioners%20Non%20Inverter:relevance',\n",
    "'https://www.reliancedigital.in/search?q=Single%20Door%20Refrigerators:relevance',\n",
    "'https://www.reliancedigital.in/search?q=Ceiling%20Fans:relevance'\n",
    "]\n",
    "\n",
    "for w in range(len(list)):\n",
    "    category=str(cc[w])\n",
    "    driver.get(str(list[w]))\n",
    "    try:\n",
    "        driver.find_element(by=By.XPATH, value='/html/body/div[5]/div[2]/div[3]/button[1]').click()\n",
    "    except:\n",
    "        pass\n",
    "    #Get product link\n",
    "    title=[]\n",
    "    link=[]\n",
    "    a=driver.find_element(by=By.CLASS_NAME, value='pl__headline').text\n",
    "    a=a.split(' ')\n",
    "    a=math.floor(int(a[-2])/24)\n",
    "    for i in range(a+1):\n",
    "        try:\n",
    "            driver.get(str(list[w])+'&page='+str(i))\n",
    "            time.sleep(1)\n",
    "            job=driver.find_element(by=By.CLASS_NAME, value='pl__container')\n",
    "            soup=BeautifulSoup(job.get_attribute('innerHTML'),'html.parser')\n",
    "            a=soup.find_all(\"a\",class_=\"\")\n",
    "            for job_elem in a:\n",
    "                link.append('https://www.reliancedigital.in'+job_elem['href'])\n",
    "            c=soup.find_all(\"p\",class_=\"sp__name\")\n",
    "            for job_elem in c:\n",
    "                title.append(job_elem.text)\n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    df = pd.DataFrame({\n",
    "    'Title': title,\n",
    "    'Link': link})\n",
    "    df.to_excel(str(category)+'.xlsx')\n",
    "\n",
    "    #Get images link\n",
    "    driver.implicitly_wait(0)\n",
    "    About=[]\n",
    "    prodDetails=[]\n",
    "    specs=[]\n",
    "    mainimg=[]\n",
    "    for j in range(0,len(df)):\n",
    "        img=[]\n",
    "        print(j)\n",
    "        driver.get(df['Link'][j])\n",
    "        try:\n",
    "            job=driver.find_element(by=By.CLASS_NAME, value='infiniteScroller')\n",
    "            job=driver.find_element(by=By.CLASS_NAME, value='infiniteScroller')\n",
    "            job=driver.find_element(by=By.CLASS_NAME, value='infiniteScroller')\n",
    "            soup=BeautifulSoup(job.get_attribute('innerHTML'),'html.parser')\n",
    "            a=soup.find(\"div\",class_=\"blk__sm__7 flush__left pdp__topBlock\")\n",
    "            About.append(a.text)\n",
    "        except:\n",
    "            About.append('none')\n",
    "        try:\n",
    "            a=soup.find(\"div\",class_=\"pdp__tab-info\")\n",
    "            prodDetails.append(a.text)\n",
    "        except:\n",
    "            prodDetails.append('none')\n",
    "        try:\n",
    "            a=soup.find(\"div\",id=\"pdp__specification\")\n",
    "            specs.append(a.text)\n",
    "        except:\n",
    "            specs.append('none')\n",
    "        try:\n",
    "            driver.find_element(by=By.ID, value='RIl_PDPSlideShow').click()\n",
    "            time.sleep(1)\n",
    "            d=driver.find_elements(by=By.CLASS_NAME, value='mb__16')\n",
    "            l=len(d)\n",
    "            for i in range(l):\n",
    "                try:\n",
    "                    d[i].click()\n",
    "                    job=driver.find_element(by=By.XPATH, value='/html/body/div[1]/main/div[2]/div/section[1]/div[1]/div[3]/div[2]/div/div/div/div[2]/div/div[2]/div[2]')\n",
    "                    soup=BeautifulSoup(job.get_attribute('innerHTML'),'html.parser')\n",
    "                    a=soup.find_all(\"img\",class_=\"\")\n",
    "                    for item in a:\n",
    "                        img.append('https://www.reliancedigital.in/'+item['src'])\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            img.append('none')\n",
    "        mainimg.append(img)\n",
    "\n",
    "    df['Points']=0\n",
    "    df['image link']=0\n",
    "    df['prodDetails']=0\n",
    "    df['Specs']=0\n",
    "    df['Points']=About\n",
    "    df['Specs']=specs\n",
    "    df['prodDetails']=prodDetails\n",
    "    df['image link']=mainimg\n",
    "    df.to_csv('final'+str(category)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4c5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f6723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
