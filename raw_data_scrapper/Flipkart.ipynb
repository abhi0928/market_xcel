{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.filedialog as fd\n",
    "from selenium.webdriver.common.by import By\n",
    "# root = tk.Tk()\n",
    "# file = fd.askopenfilename(parent=root, title='Choose a record file')\n",
    "# file2 = fd.askopenfilenames(parent=root, title='Choose a pdf files')\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from IPython.display import clear_output\n",
    "# root.destroy()\n",
    "from time import sleep\n",
    "import easygui\n",
    "import time\n",
    "import re\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c766a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "#set chromedriver.exe path\n",
    "driver = webdriver.Chrome(executable_path=\"C:\\chromedriver.exe\")\n",
    "driver.implicitly_wait(0)\n",
    "#maximize browser\n",
    "driver.maximize_window()\n",
    "#launch URL\n",
    "driver.get(\"https://www.flipkart.com/search?q=Frost%20Free%20refrigerator&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5748acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=['LED Lamps','RAC (Fixed speed)']\n",
    "\n",
    "list=[\n",
    "'https://www.flipkart.com/search?q=LED%20Lights&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off',\n",
    "'https://www.flipkart.com/search?q=Air%20Conditioners%20Non%20Inverter&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off'\n",
    "]\n",
    "\n",
    "for w1 in range(len(list)):\n",
    "    category=str(cc[w1])\n",
    "    driver.get(str(list[w1]))\n",
    "\n",
    "    #Get product link\n",
    "    title=[]\n",
    "    link=[]\n",
    "    limit=0\n",
    "    while True:\n",
    "        try:\n",
    "            if(limit<42):\n",
    "                limit+=1\n",
    "                time.sleep(1)\n",
    "                job=driver.find_element(by=By.ID, value='container')\n",
    "                soup=BeautifulSoup(job.get_attribute('innerHTML'),'html.parser')\n",
    "                a=soup.find_all(\"a\",class_=\"_1fQZEK\")\n",
    "                for job_elem in a:\n",
    "                    link.append('https://www.flipkart.com'+job_elem['href'])\n",
    "                c=soup.find_all(\"div\",class_=\"_4rR01T\")\n",
    "                for job_elem in c:\n",
    "                    title.append(job_elem.text)\n",
    "                try:\n",
    "                    driver.find_element(by=By.XPATH, value='/html/body/div/div/div[3]/div[1]/div[2]/div[26]/div/div/nav/a[11]/span').click()\n",
    "                except:\n",
    "                    try:\n",
    "                        driver.find_element(by=By.XPATH, value='/html/body/div/div/div[3]/div[1]/div[2]/div[26]/div/div/nav/a[12]/span').click()\n",
    "                    except:\n",
    "                        break\n",
    "        #         b=soup.find(\"a\",class_=\"_1LKTO3\")['href']\n",
    "        #         driver.get('https://www.flipkart.com'+b)\n",
    "        #         print(len(link))\n",
    "        #         print(len(title))\n",
    "            else:\n",
    "                raise error\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'Title': title,\n",
    "    'Link': link})\n",
    "    df.to_excel(str(category)+'.xlsx')\n",
    "#     len(df)\n",
    "\n",
    "    #Get images link\n",
    "    driver.implicitly_wait(0)\n",
    "    specs=[]\n",
    "    prodDescp=[]\n",
    "    mainimg=[]\n",
    "    # for j in range(0,1):\n",
    "    for j in range(0,len(df)):\n",
    "        print(j)\n",
    "        driver.get(df['Link'][j])\n",
    "    #     break\n",
    "        try:\n",
    "            img=[]\n",
    "            job=driver.find_element(by=By.CLASS_NAME, value='_3GnUWp')\n",
    "            soup=BeautifulSoup(job.get_attribute('innerHTML'),'html.parser')\n",
    "            a=soup.find_all(\"img\",class_=\"q6DClP\")\n",
    "            for item in a:\n",
    "                img.append(item['src'].replace(\"image/128/128/\", \"image/416/416/\"))\n",
    "        #         print(item['src'].replace(\"image/128/128/\", \"image/416/416/\"))\n",
    "            mainimg.append(img)\n",
    "        except:\n",
    "            mainimg.append('none')\n",
    "\n",
    "        #view all features\n",
    "        for l in range(7,10):\n",
    "            for k in range(2,6):\n",
    "                try:\n",
    "                    driver.find_element(by=By.XPATH, value='/html/body/div[1]/div/div[3]/div[1]/div[2]/div['+str(l)+']/div['+str(k)+']/button').click()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "        #Read More\n",
    "        for l in range(7,10):\n",
    "            for k in range(2,6):\n",
    "                try:\n",
    "                    driver.find_element(by=By.XPATH, value='/html/body/div[1]/div/div[3]/div[1]/div[2]/div['+str(l)+']/div['+str(k)+']/div/div[2]/button').click()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        #close\n",
    "        try:\n",
    "            driver.find_element(by=By.XPATH, value='/html/body/div[3]/div/div/button').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        time.sleep(0.5)\n",
    "        #specifications\n",
    "        try:\n",
    "            x=driver.find_element(by=By.CLASS_NAME, value='_1UhVsV').text\n",
    "            specs.append(x)\n",
    "        except:\n",
    "            specs.append('none')\n",
    "\n",
    "        #Product Description\n",
    "        try:\n",
    "            d=driver.find_elements(by=By.CLASS_NAME, value='_2k6Cpt')\n",
    "            z1=''\n",
    "            for y in d:\n",
    "                z1=y.text + z1 + ' '\n",
    "            prodDescp.append(z1)\n",
    "        except:\n",
    "            prodDescp.append('none')\n",
    "\n",
    "\n",
    "    df['specs']=0\n",
    "    df['image link']=0\n",
    "    df['prodDescp']=0\n",
    "    df['specs']=specs\n",
    "    df['prodDescp']=prodDescp\n",
    "    df['image link']=mainimg\n",
    "    df.to_csv('final'+str(category)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373245f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9ce48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ef516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b8610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
